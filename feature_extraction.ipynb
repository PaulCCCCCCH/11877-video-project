{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature-extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKq2FdQFtqfB"
      },
      "outputs": [],
      "source": [
        "!pip install wav2clip\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import librosa\n",
        "from PIL import Image\n",
        "import wav2clip\n",
        "import clip"
      ],
      "metadata": {
        "id": "8pFSyqwltz1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7xPn0k3M7ML2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_PATH = \"/content/drive/Othercomputers/My MacBook Pro/GitHub/wav2clip/audio\" # Change to audio files path\n",
        "IMAGE_PATH = \"/content/drive/Othercomputers/My MacBook Pro/GitHub/wav2clip/image\" # Change to image files path\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "audio_model = wav2clip.get_model()\n",
        "language_and_vision_model, preprocess = clip.load(\"ViT-B/32\", device=device)"
      ],
      "metadata": {
        "id": "ecL2QYdnvdqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio"
      ],
      "metadata": {
        "id": "2nWP_1xs6l7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_1, sr = librosa.load(f\"{AUDIO_PATH}/bicycle.wav\")\n",
        "audio_features_1 = wav2clip.embed_audio(audio_1, audio_model)\n",
        "audio_features_2 = wav2clip.embed_audio(audio_2, audio_model)\n",
        "# print(audio_features_1)"
      ],
      "metadata": {
        "id": "v_pUuK821ww_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language"
      ],
      "metadata": {
        "id": "CigVUy9Q6o2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = \"bicycle\"\n",
        "text_2 = \"camera\"\n",
        "text_features_1 = language_and_vision_model.encode_text(clip.tokenize(text_1).to(device))\n",
        "text_features_2 = language_and_vision_model.encode_text(clip.tokenize(text_2).to(device))\n",
        "text_features_1 /= text_features_1.norm(dim=-1, keepdim=True)\n",
        "text_features_2 /= text_features_2.norm(dim=-1, keepdim=True)\n",
        "# print(text_features_1)"
      ],
      "metadata": {
        "id": "L6mmffok1ue5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vision"
      ],
      "metadata": {
        "id": "IJx8zyGj6q3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_1 = Image.open(f\"{IMAGE_PATH}/bicycle.jpg\")\n",
        "image_2 = Image.open(f\"{IMAGE_PATH}/camera.jpg\")\n",
        "image_features_1 = language_and_vision_model.encode_image(preprocess(image_1).unsqueeze(0).to(device))\n",
        "image_features_2 = language_and_vision_model.encode_image(preprocess(image_2).unsqueeze(0).to(device))\n",
        "image_features_1 /= image_features_1.norm(dim=-1, keepdim=True)\n",
        "image_features_2 /= image_features_2.norm(dim=-1, keepdim=True)\n",
        "# print(image_features_1)"
      ],
      "metadata": {
        "id": "Cs2l6vzH6sXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sim(x, y):\n",
        "  return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
        "\n",
        "audio = np.squeeze(np.asarray(audio_features_1))\n",
        "audio_diff = np.squeeze(np.asarray(audio_features_2))\n",
        "text = np.squeeze(np.asarray(text_features_1.detach().cpu()))\n",
        "image = np.squeeze(np.asarray(image_features_1.detach().cpu()))\n",
        "\n",
        "# Audio (bicycle) vs. Audio (camera) (different semantics, same modality)\n",
        "print(f\"audio-audio similarity: {sim(audio, audio_diff)}\")\n",
        "\n",
        "# Audio (bicycle) vs. Text (bicycle) (same semantics, different modality)\n",
        "print(f\"audio-text similarity: {sim(audio, text)}\")\n",
        "\n",
        "# Audio (bicycle) vs. Image (bicycle) (same semantics, different modality)\n",
        "print(f\"audio-image similarity: {sim(audio, image)}\")"
      ],
      "metadata": {
        "id": "qjMwfTJpxE37"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}