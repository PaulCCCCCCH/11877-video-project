{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b258ac68-2786-41e1-8375-c66061247acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision as vis\n",
    "from torch.utils import data\n",
    "from torch.nn.utils.rnn import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "import os, sys\n",
    "\n",
    "has_cuda = torch.cuda.is_available()\n",
    "# has_cuda = False\n",
    "is_windows = sys.platform == \"win32\"\n",
    "\n",
    "if has_cuda:\n",
    "  print(torch.cuda.get_device_name(0))\n",
    "else:\n",
    "  print(\"CPU\")\n",
    "device = torch.device(\"cuda:0\" if has_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4137aa3-9269-4bd2-a407-f7ff229547f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_helper import ModelSaver, load_model, model_store, StoredModel\n",
    "from dataset.triplet_dataset import TextTripletDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e99c1e0-c360-498f-8930-027be95fa7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextTripletDataset(\n",
    "  \"subset_splits/train_set.csv\",\n",
    "  \"/home/ubuntu/data/transcriptions\",\n",
    "  300)\n",
    "\n",
    "# validation_dataset = TextTripletDataset(\n",
    "#   \"subset_splits/val_set.csv\",\n",
    "#   \"/home/ubuntu/data/transcriptions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6fddfa3-2e22-4456-9d0c-c46b08b39acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_args = dict(batch_size=256,\n",
    "                             num_workers=torch.get_num_threads() * 2 if not is_windows else 0) if has_cuda else dict(batch_size=64)\n",
    "train_dataloader_args[\"shuffle\"] = True\n",
    "train_dataloader_args[\"collate_fn\"] = TextTripletDataset.collate_fn\n",
    "\n",
    "# validation_dataloader_args = train_dataloader_args.copy()\n",
    "# validation_dataloader_args[\"shuffle\"] = False\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, **train_dataloader_args)\n",
    "# validation_dataloader = data.DataLoader(validation_dataset, **validation_dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e603d3e-05d3-41a4-bdc1-297e6ba17801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.language_model import LSTMLanguageModel, get_last_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85353d6f-f49a-43f9-ad88-e1c31eceb226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resuming from last checkpoint epoch_18\n"
     ]
    }
   ],
   "source": [
    "model_id = \"lang_model_01\"\n",
    "epoch_start, model, optimizer, scheduler, criterion = load_model(model_id, device, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4536538d-4bdd-4eb8-be83-1bfe933c105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMLanguageModel(\n",
      "  (embedding): Embedding(49408, 400)\n",
      "  (rnn): Sequential(\n",
      "    (0): LSTM(400, 1500)\n",
      "    (1): LockedDropout(p=0.2)\n",
      "    (2): LSTM(1500, 1500)\n",
      "    (3): LockedDropout(p=0.2)\n",
      "    (4): LSTM(1500, 400)\n",
      "  )\n",
      "  (word_prob): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_id = \"lang_model_02\"\n",
    "\n",
    "model = LSTMLanguageModel(vocab_size = 49408)\n",
    "\n",
    "epoch_start = 1\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91b42b62-6d25-4ffc-bb0f-ab58e6416f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  os.mkdir(f\"{model_store}/{model_id}\")\n",
    "except:\n",
    "  print(\"WARN: Directory exists\")\n",
    "# save model summary to a txt file\n",
    "with open(f\"{model_store}/{model_id}/model_spec.txt\", \"w\") as file:\n",
    "  file.write(str(model) + \"\\n\")\n",
    "  # file.write(model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "642487c6-5b49-45f5-b59e-0e65047b5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, dataloader):\n",
    "  cumulative_stats = {\n",
    "    \"loss\": 0.0\n",
    "  }\n",
    "  \n",
    "  num_batches = 0\n",
    "  \n",
    "  prog_bar = tqdm(dataloader, desc=\"Train\" if model.training else \"Eval \")\n",
    "\n",
    "  for (anchor, anchor_len), (positive, positive_len), (negative, negative_len) in prog_bar:\n",
    "    anchor = anchor.to(device)\n",
    "    positive = positive.to(device)\n",
    "    negative = negative.to(device)\n",
    "\n",
    "    num_batches += 1\n",
    "    \n",
    "    if model.training:\n",
    "      optimizer.zero_grad() # clear calculated gradients\n",
    "      \n",
    "    with torch.cuda.amp.autocast():\n",
    "      # slice off special sos token, discount eos token\n",
    "      # import pdb\n",
    "      # pdb.set_trace()\n",
    "      loss = criterion(get_last_element(model(anchor[:, 1:])[0], anchor_len - 2),\n",
    "                      get_last_element(model(positive[:, 1:])[0], positive_len - 2),\n",
    "                      get_last_element(model(negative[:, 1:])[0], negative_len - 2))\n",
    "    \n",
    "    if model.training:        \n",
    "      # backprop loss\n",
    "      scaler.scale(loss).backward()\n",
    "      scaler.step(optimizer)\n",
    "      scaler.update()\n",
    "      \n",
    "    # accumulate and display stats\n",
    "    cumulative_stats[\"loss\"] += loss.item()\n",
    "    \n",
    "    prog_bar.set_postfix(loss=f'{cumulative_stats[\"loss\"] / num_batches:.6f}')\n",
    "  \n",
    "  # average stats across batches\n",
    "  cumulative_stats[\"loss\"] /= len(dataloader)\n",
    "  \n",
    "  return cumulative_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b12e0d03-82d9-4672-b2dc-63b8228f7043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Model\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from itertools import chain\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "if epoch_start == 1:\n",
    "  # define only at the start of the training\n",
    "  print(\"New Model\")\n",
    "  \n",
    "  regularization = 3e-5\n",
    "  learning_rate = 1e-3\n",
    "  criterion = nn.TripletMarginLoss(margin=0.2)\n",
    "  # criterion = nn.TripletMarginWithDistanceLoss(distance_function=nn.CosineSimilarity(), margin=0.1)\n",
    "  optimizer = optim.Adam(chain(model.parameters(), criterion.parameters()),\n",
    "                         lr = learning_rate, weight_decay=regularization)\n",
    "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 6, gamma = 0.5)\n",
    "else:\n",
    "  print(\"Existing Model\")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler() # mix-precision training\n",
    "model_saver = ModelSaver(model_id, mode=\"min\", regular_save_interval=5)\n",
    "\n",
    "with open(f\"{model_store}/{model_id}/training_params.txt\", \"w\") as file:\n",
    "  file.write(f\"num_epochs = {num_epochs}\\n\")\n",
    "  file.write(f\"criterion = {criterion}\\n\")\n",
    "  file.write(f\"optimizer = {optimizer}\\n\")\n",
    "  file.write(f\"scheduler = {type(scheduler).__name__}({scheduler.state_dict()})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d40a0-19bf-4c5f-9731-7310ae2a61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "import json\n",
    "\n",
    "print(f\"Model: {model_id}. Training for {num_epochs} epochs\", file=sys.stderr)\n",
    "\n",
    "for epoch in range(epoch_start, num_epochs + 1):\n",
    "  print(f\"Epoch {epoch}\", file=sys.stderr)\n",
    "  \n",
    "  # set model in training mode\n",
    "  model.train()\n",
    "  train_stats = run_model(model, train_dataloader)\n",
    "  \n",
    "  # set model to eval mode\n",
    "  # model.eval()\n",
    "  # with torch.no_grad():\n",
    "  #   eval_stats = run_model(model, validation_dataloader)\n",
    "    \n",
    "  # let scheduler know it's the next epoch\n",
    "#   scheduler.step(eval_stats[\"accuracy\"])\n",
    "  \n",
    "  stats = {\n",
    "    \"epoch\": epoch,\n",
    "    \"train_stats\": train_stats,\n",
    "    # \"eval_stats\": eval_stats,\n",
    "    \"learning rate\": optimizer.param_groups[0][\"lr\"]\n",
    "  }\n",
    "  \n",
    "  scheduler.step()\n",
    "  \n",
    "  if math.isnan(train_stats[\"loss\"]):\n",
    "    print(\"NaN loss detected! Stop Training\")\n",
    "    break\n",
    "    \n",
    "  model_saver.save(StoredModel(model, optimizer, scheduler, criterion), stats, train_stats[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5216b567-09f6-4192-88ea-23bb5f2cb348",
   "metadata": {},
   "source": [
    "## Extract CLIP text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15949dac-e3b5-47d6-9c0a-643242fac88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "# pip install git+https://github.com/openai/CLIP.git\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d1b4b97-2447-4bca-8f2f-db70593f63e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def read_texts(split, transcript_base):\n",
    "  split = pd.read_csv(split)\n",
    "  text_list = list()\n",
    "  for _, (cat, vid) in split.iterrows():\n",
    "    with open(f\"{transcript_base}/{cat}/{vid}.txt\") as file:\n",
    "      text = file.readline().strip()\n",
    "      text_list.append(text)\n",
    "  return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8dfc65a-c378-4ac6-ad2b-efaa359e1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = read_texts(\"subset_splits/train_set.csv\", \"/home/ubuntu/data/transcriptions\")\n",
    "val_text = read_texts(\"subset_splits/val_set.csv\", \"/home/ubuntu/data/transcriptions\")\n",
    "test_text = read_texts(\"subset_splits/test_set.csv\", \"/home/ubuntu/data/transcriptions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5a386f9-ffb0-430d-ad23-98d1529760fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.triplet_dataset import tokenize\n",
    "def get_embeddings(text_list, batch_size=512):\n",
    "  num_batches = (len(text_list) - 1) // batch_size + 1\n",
    "  embeddings = list()\n",
    "  with torch.no_grad():\n",
    "    for i in range(num_batches):\n",
    "      tokenized_text, _ = tokenize(text_list[i * batch_size: (i + 1) * batch_size])\n",
    "      embeddings.append(clip_model.encode_text(tokenized_text.to(device)))\n",
    "      \n",
    "  return torch.cat(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b078e63-64c7-4ba3-8d10-db1198e658aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = get_embeddings(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b486776-1fdb-4f51-948e-21044252c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(t, \"clip_embeddings/train_text.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033d4a6-cb39-42de-bd4b-46a1cb9e7f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
